{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKq5vgbI3QOi"
   },
   "source": [
    "##**Assignment 3 (2024/2): ML1**\n",
    "**Safe to eat or deadly poison?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtWlAnW-4IIw"
   },
   "source": [
    "This homework is a classification task to identify whether a mushroom is edible or poisonous.\n",
    "\n",
    "This dataset includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family Mushroom drawn from The Audubon Society Field Guide to North American Mushrooms (1981).\n",
    "\n",
    "Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the credibility of a mushroom; no rule like \"leaflets three, let it be'' for Poisonous Oak and Ivy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ia90I1DY4hYT"
   },
   "source": [
    "Step 1. Load 'mushroom2020_dataset.csv' data from the “Attachment” (note: this data set has been preliminarily prepared.).\n",
    "\n",
    "Step 2. Drop rows where the target (label) variable is missing.\n",
    "\n",
    "Step 3. Drop the following variables:\n",
    "'id','gill-attachment', 'gill-spacing', 'gill-size','gill-color-rate', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring-rate','stalk-color-below-ring-rate','veil-color-rate','veil-type'\n",
    "\n",
    "Step 4. Examine the number of rows, the number of digits, and whether any are missing.\n",
    "\n",
    "Step 5. Fill missing values by adding the mean for numeric variables and the mode for nominal variables.\n",
    "\n",
    "Step 6. Convert the label variable e (edible) to 1 and p (poisonous) to 0 and check the quantity. class0: class1\n",
    "\n",
    "Step 7. Convert the nominal variable to numeric using a dummy code with drop_first = True.\n",
    "\n",
    "Step 8. Split train/test with 20% test, stratify, and seed = 2020.\n",
    "\n",
    "Step 9. Create a Random Forest with GridSearch on training data with 5 CV.\n",
    "\t'criterion':['gini','entropy']\n",
    "'max_depth': [2,3]\n",
    "'min_samples_leaf':[2,5]\n",
    "'N_estimators':[100]\n",
    "'random_state': 2020\n",
    "\n",
    "Step 10.  Predict the testing data set with classification_report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEoNW_114VQh"
   },
   "source": [
    "**Complete class MushroomClassifier from given code template below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-Xw2UEzU3s0k"
   },
   "outputs": [],
   "source": [
    "#import your other libraries here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# hint\n",
    "# import from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import ...\n",
    "# from sklearn.ensemble import ...\n",
    "# from sklearn.metrics import ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "j59N5vzD3P1Z"
   },
   "outputs": [],
   "source": [
    "class MushroomClassifier:\n",
    "    def __init__(self, data_path): # DO NOT modify this line\n",
    "        self.data_path = data_path\n",
    "        self.df = pd.read_csv(data_path)\n",
    "\n",
    "    def Q1(self): # DO NOT modify this line\n",
    "        \"\"\"\n",
    "            1. (From step 1) Before doing the data prep., how many \"na\" are there in \"gill-size\" variables?\n",
    "        \"\"\"\n",
    "        # remove pass and replace with you code\n",
    "        return self.df['gill-size'].isnull().sum()\n",
    "\n",
    "\n",
    "    def Q2(self): # DO NOT modify this line\n",
    "        \"\"\"\n",
    "            2. (From step 2-4) How many rows of data, how many variables?\n",
    "            - Drop rows where the target (label) variable is missing.\n",
    "            - Drop the following variables:\n",
    "            'id','gill-attachment', 'gill-spacing', 'gill-size','gill-color-rate','stalk-root', 'stalk-surface-above-ring',\n",
    "            'stalk-surface-below-ring', 'stalk-color-above-ring-rate','stalk-color-below-ring-rate','veil-color-rate','veil-type'\n",
    "            - Examine the number of rows, the number of digits, and whether any are missing.\n",
    "        \"\"\"\n",
    "        # remove pass and replace with you code\n",
    "        self.df = self.df.dropna(subset=['label'])\n",
    "        self.df = self.df.drop(columns=['id','gill-attachment', 'gill-spacing', 'gill-size','gill-color-rate','stalk-root', 'stalk-surface-above-ring',\n",
    "            'stalk-surface-below-ring', 'stalk-color-above-ring-rate','stalk-color-below-ring-rate','veil-color-rate','veil-type'])\n",
    "        return  self.df.shape\n",
    "\n",
    "\n",
    "    def Q3(self): # DO NOT modify this line\n",
    "        \"\"\"\n",
    "            3. (From step 5-6) Answer the quantity class0:class1\n",
    "            - Fill missing values by adding the mean for numeric variables and the mode for nominal variables.\n",
    "            - Convert the label variable e (edible) to 1 and p (poisonous) to 0 and check the quantity. class0: class1\n",
    "            - Note: You need to reproduce the process (code) from Q2 to obtain the correct result.\n",
    "        \"\"\"\n",
    "        # remove pass and replace with you code\n",
    "        self.df = self.df.dropna(subset=['label'])\n",
    "        self.df = self.df.drop(columns=['id','gill-attachment', 'gill-spacing', 'gill-size','gill-color-rate','stalk-root', 'stalk-surface-above-ring',\n",
    "            'stalk-surface-below-ring', 'stalk-color-above-ring-rate','stalk-color-below-ring-rate','veil-color-rate','veil-type'])\n",
    "        \n",
    "        \"\"\" -------------- \"\"\"\n",
    "\n",
    "        numeric_columns = self.df.select_dtypes(include=['number']).columns.tolist()\n",
    "        nominal_columns = self.df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "        for col in numeric_columns:\n",
    "            self.df[col] = self.df[col].fillna(self.df[col].mean())\n",
    "        for col in nominal_columns:\n",
    "            if not self.df[col].mode().empty:\n",
    "                self.df[col] = self.df[col].fillna(self.df[col].mode()[0])\n",
    "        \n",
    "        self.df['label'] = self.df['label'].map({'e': 1, 'p': 0})\n",
    "\n",
    "        result = self.df['label'].value_counts()\n",
    "\n",
    "        return (int(result.get(0,0)),int(result.get(1,0)))\n",
    "\n",
    "\n",
    "    def Q4(self): # DO NOT modify this line\n",
    "        \"\"\"\n",
    "            4. (From step 7-8) How much is each training and testing sets\n",
    "            - Convert the nominal variable to numeric using a dummy code with drop_first = True.\n",
    "            - Split train/test with 20% test, stratify, and seed = 2020.\n",
    "            - Note: You need to reproduce the process (code) from Q2, Q3 to obtain the correct result.\n",
    "        \"\"\"\n",
    "        # remove pass and replace with you code\n",
    "        self.df = self.df.dropna(subset=['label'])\n",
    "        self.df = self.df.drop(columns=['id','gill-attachment', 'gill-spacing', 'gill-size','gill-color-rate','stalk-root', 'stalk-surface-above-ring',\n",
    "            'stalk-surface-below-ring', 'stalk-color-above-ring-rate','stalk-color-below-ring-rate','veil-color-rate','veil-type'])\n",
    "        \n",
    "        \"\"\" -------------- \"\"\"\n",
    "        \n",
    "        numeric_columns = self.df.select_dtypes(include=['number']).columns.tolist()\n",
    "        nominal_columns = self.df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "        for col in numeric_columns:\n",
    "            self.df[col] = self.df[col].fillna(self.df[col].mean())\n",
    "        for col in nominal_columns:\n",
    "            if not self.df[col].mode().empty:\n",
    "                self.df[col] = self.df[col].fillna(self.df[col].mode()[0])\n",
    "        \n",
    "        self.df['label'] = self.df['label'].map({'e': 1, 'p': 0})\n",
    "\n",
    "        \"\"\" -------------- \"\"\"\n",
    "    \n",
    "        df_encoded = pd.get_dummies(self.df, drop_first=True)\n",
    "\n",
    "        X = df_encoded.drop('label', axis=1)\n",
    "        y = df_encoded['label']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2020)\n",
    "        \n",
    "        return (X_train.shape, X_test.shape)\n",
    "\n",
    "\n",
    "    def Q5(self):\n",
    "        \"\"\"\n",
    "            5. (From step 9) Best params after doing random forest grid search.\n",
    "            Create a Random Forest with GridSearch on training data with 5 CV.\n",
    "            - 'criterion':['gini','entropy']\n",
    "            - 'max_depth': [2,3]\n",
    "            - 'min_samples_leaf':[2,5]\n",
    "            - 'N_estimators':[100]\n",
    "            - 'random_state': 2020\n",
    "            - Note: You need to reproduce the process (code) from Q2, Q3, Q4 to obtain the correct result.\n",
    "        \"\"\"\n",
    "        # remove pass and replace with you code\n",
    "        self.df = self.df.dropna(subset=['label'])\n",
    "        self.df = self.df.drop(columns=['id','gill-attachment', 'gill-spacing', 'gill-size','gill-color-rate','stalk-root', 'stalk-surface-above-ring',\n",
    "            'stalk-surface-below-ring', 'stalk-color-above-ring-rate','stalk-color-below-ring-rate','veil-color-rate','veil-type'])\n",
    "        \n",
    "        \"\"\" -------------- \"\"\"\n",
    "        \n",
    "        numeric_columns = self.df.select_dtypes(include=['number']).columns.tolist()\n",
    "        nominal_columns = self.df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "        for col in numeric_columns:\n",
    "            self.df[col] = self.df[col].fillna(self.df[col].mean())\n",
    "        for col in nominal_columns:\n",
    "            if not self.df[col].mode().empty:\n",
    "                self.df[col] = self.df[col].fillna(self.df[col].mode()[0])\n",
    "        \n",
    "        self.df['label'] = self.df['label'].map({'e': 1, 'p': 0})\n",
    "\n",
    "        \"\"\" -------------- \"\"\"\n",
    "    \n",
    "        df_encoded = pd.get_dummies(self.df, drop_first=True)\n",
    "\n",
    "        X = df_encoded.drop('label', axis=1)\n",
    "        y = df_encoded['label']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2020)\n",
    "\n",
    "        \"\"\" -------------- \"\"\"\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=RandomForestClassifier(random_state=2020),\n",
    "            param_grid={\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': [2, 3],\n",
    "                'min_samples_leaf': [2, 5],\n",
    "                'n_estimators': [100],\n",
    "            },\n",
    "            cv=5,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_params = grid_search.best_params_\n",
    "        criterion = best_params['criterion']\n",
    "        max_depth = best_params['max_depth']\n",
    "        min_samples_leaf = best_params['min_samples_leaf']\n",
    "        n_estimators = best_params['n_estimators']\n",
    "        return (criterion, max_depth, min_samples_leaf, n_estimators, 2020) \n",
    "        \n",
    "\n",
    "\n",
    "    def Q6(self):\n",
    "        \"\"\"\n",
    "            5. (From step 10) What is the value of macro f1 (2 digits)?\n",
    "            Predict the testing data set with confusion_matrix and classification_report,\n",
    "            using scientific rounding (less than 0.5 dropped, more than 0.5 then increased)\n",
    "            - Note: You need to reproduce the process (code) from Q2, Q3, Q4, Q5 to obtain the correct result.\n",
    "        \"\"\"\n",
    "        self.df = self.df.dropna(subset=['label'])\n",
    "        self.df = self.df.drop(columns=['id','gill-attachment', 'gill-spacing', 'gill-size','gill-color-rate','stalk-root', 'stalk-surface-above-ring',\n",
    "            'stalk-surface-below-ring', 'stalk-color-above-ring-rate','stalk-color-below-ring-rate','veil-color-rate','veil-type'])\n",
    "        \n",
    "        \"\"\" -------------- \"\"\"\n",
    "        \n",
    "        numeric_columns = self.df.select_dtypes(include=['number']).columns.tolist()\n",
    "        nominal_columns = self.df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "        for col in numeric_columns:\n",
    "            self.df[col] = self.df[col].fillna(self.df[col].mean())\n",
    "        for col in nominal_columns:\n",
    "            if not self.df[col].mode().empty:\n",
    "                self.df[col] = self.df[col].fillna(self.df[col].mode()[0])\n",
    "        \n",
    "        self.df['label'] = self.df['label'].map({'e': 1, 'p': 0})\n",
    "\n",
    "        \"\"\" -------------- \"\"\"\n",
    "    \n",
    "        df_encoded = pd.get_dummies(self.df, drop_first=True)\n",
    "\n",
    "        X = df_encoded.drop('label', axis=1)\n",
    "        y = df_encoded['label']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2020)\n",
    "\n",
    "        \"\"\" -------------- \"\"\"\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=RandomForestClassifier(random_state=2020),\n",
    "            param_grid={\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': [2, 3],\n",
    "                'min_samples_leaf': [2, 5],\n",
    "                'n_estimators': [100],\n",
    "            },\n",
    "            cv=5,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_params = grid_search.best_params_\n",
    "        criterion = best_params['criterion']\n",
    "        max_depth = best_params['max_depth']\n",
    "        min_samples_leaf = best_params['min_samples_leaf']\n",
    "        n_estimators = best_params['n_estimators']\n",
    "\n",
    "        \"\"\" -------------- \"\"\"\n",
    "\n",
    "        best_params = {\n",
    "            'criterion': criterion,\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_leaf': min_samples_leaf,\n",
    "            'n_estimators': n_estimators,\n",
    "            'random_state': 2020,\n",
    "        }\n",
    "        rf = RandomForestClassifier(**best_params)\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = rf.predict(X_test)\n",
    "\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        f1_class0 = np.round(report['0']['f1-score'], 2)\n",
    "        f1_class1 = np.round(report['1']['f1-score'], 2)\n",
    "\n",
    "        return (float(f1_class0), float(f1_class1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "macBnE5U5KYm"
   },
   "source": [
    "Run the code below to test that your code can work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eGpwReMy3NCI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "(5764, 12)\n",
      "(3660, 2104)\n",
      "((4611, 42), (1153, 42))\n",
      "('gini', 3, 5, 100, 2020)\n",
      "(0.98, 0.97)\n"
     ]
    }
   ],
   "source": [
    "hw = MushroomClassifier('mushroom2020_dataset.csv')\n",
    "\n",
    "print(hw.Q1())\n",
    "print(hw.Q2())\n",
    "print(hw.Q3())\n",
    "print(hw.Q4())\n",
    "print(hw.Q5())\n",
    "print(hw.Q6())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
